{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import merge\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from skimage.transform import rescale, resize\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp(I):\n",
    "    I = np.uint8(I)\n",
    "    cv2.imshow('image', I)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = 'Resized_Data/Ground_truth/gt'\n",
    "melanoma_input = 'Resized_Data/Melanoma/melanoma'\n",
    "melanoma_output_training = 'Partitioned_Data/Training/1_Melanoma'\n",
    "melanoma_output_validation = 'Partitioned_Data/Validation/1_Melanoma'\n",
    "others_input = 'Resized_Data/Others/others'\n",
    "others_output_training = 'Partitioned_Data/Training/0_Others'\n",
    "others_output_validation = 'Partitioned_Data/Validation/0_Others'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Resize and Partitioning\n",
    "\n",
    "Image is multiplied with the ground truth to give the region of interest and then resized the input size of the CNN ( 64 X 64 ).\n",
    "It is partitioned 90:10 ratio between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "melanoma_length = len(os.listdir(melanoma_input))\n",
    "for image_name in os.listdir(melanoma_input):\n",
    "    counter = counter + 1\n",
    "    image = cv2.imread(os.path.join(melanoma_input,image_name))\n",
    "    ground_image_name = image_name[:12] + '_segmentation.png'\n",
    "    gt_image = cv2.imread(os.path.join(gt_path,ground_image_name))\n",
    "    gt_image = cv2.threshold(gt_image,127,255,cv2.THRESH_BINARY)[1]\n",
    "    gt_image = gt_image / 255.0\n",
    "    image = image * gt_image\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    if counter <= 0.9 * melanoma_length:\n",
    "        cv2.imwrite(os.path.join(melanoma_output_training, image_name), image)\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(melanoma_output_validation, image_name), image)\n",
    "    \n",
    "counter = 0\n",
    "others_length = len(os.listdir(others_input))\n",
    "for image_name in os.listdir(others_input):\n",
    "    counter = counter + 1\n",
    "    image = cv2.imread(os.path.join(others_input,image_name))\n",
    "    ground_image_name = image_name[:12] + '_segmentation.png'\n",
    "    gt_image = cv2.imread(os.path.join(gt_path,ground_image_name))\n",
    "    gt_image = cv2.threshold(gt_image,127,255,cv2.THRESH_BINARY)[1]\n",
    "    gt_image = gt_image / 255.0\n",
    "    image = image * gt_image\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    if counter <= 0.9 * others_length:\n",
    "        cv2.imwrite(os.path.join(others_output_training, image_name), image)\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(others_output_validation, image_name), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_input_size = [64, 64, 3]\n",
    "trained_classifier_path = 'Trained/classifier.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-loss\n",
    "This loss was designed to directly maximize the f1-score.  \n",
    "Using this loss did not give much improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "    TP = K.sum(y_true * y_pred)\n",
    "    soft_precision_positive = TP / (K.sum(y_pred) + 1e-7)\n",
    "    soft_recall_positive = TP / (K.sum(y_true) + 1e-7)\n",
    "    f1_loss_positive = 2 * soft_precision_positive * soft_recall_positive / (soft_precision_positive + soft_recall_positive + 1e-7)\n",
    "    TN = K.sum((1 - y_true) * (1 - y_pred))\n",
    "    soft_precision_negative = TN / (K.sum(1 - y_pred) + 1e-7)\n",
    "    soft_recall_negative = TN / (K.sum(1 - y_true) + 1e-7)\n",
    "    f1_loss_negative = 2 * soft_precision_negative * soft_recall_negative / (soft_precision_negative + soft_recall_negative + 1e-7)\n",
    "    return 1 - (0.99 * f1_loss_positive + 0.01 * f1_loss_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Binary Cross-Entropy\n",
    "This loss was designed to balance the skewness of the dataset towards the non-melanoma images.  \n",
    "This loss had been used but did not give much improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    return -K.sum(0.99 * y_true * K.log(y_pred + 1e-7) + 0.01 * (1 - y_true) * K.log(1 - y_pred + 1e-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 94,433\n",
      "Trainable params: 94,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = CNN_input_size, activation = 'relu', padding = 'same', name = 'conv1'))\n",
    "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape = CNN_input_size, activation = 'relu', padding = 'same', name = 'conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape = CNN_input_size, activation = 'relu', padding = 'same', name = 'conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape = CNN_input_size, activation = 'relu', padding = 'same', name = 'conv4'))\n",
    "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu', name = 'dense_1'))\n",
    "model.add(Dense(1, name = 'dense_2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(trained_classifier_path, monitor = 'val_loss', save_best_only = True, verbose = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1799 images belonging to 2 classes.\n",
      "Found 201 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.5116 - acc: 0.5798 - val_loss: 0.7882 - val_acc: 0.2438\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78821, saving model to Trained/classifier.h5\n",
      "Epoch 2/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.5033 - acc: 0.6227 - val_loss: 0.8235 - val_acc: 0.2935\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.4508 - acc: 0.6459 - val_loss: 0.8864 - val_acc: 0.2438\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.3869 - acc: 0.6891 - val_loss: 0.8462 - val_acc: 0.3234\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.3298 - acc: 0.7336 - val_loss: 0.7061 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.78821 to 0.70607, saving model to Trained/classifier.h5\n",
      "Epoch 6/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.1696 - acc: 0.7907 - val_loss: 0.9663 - val_acc: 0.4279\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.0817 - acc: 0.8302 - val_loss: 0.7825 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.0347 - acc: 0.8420 - val_loss: 0.7981 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/25\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.9921 - acc: 0.8569 - val_loss: 0.8016 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.9177 - acc: 0.8770 - val_loss: 0.9654 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.8496 - acc: 0.8972 - val_loss: 0.9011 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/25\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.9133 - acc: 0.8782 - val_loss: 0.8573 - val_acc: 0.6219\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.9020 - acc: 0.8847 - val_loss: 0.8347 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.8563 - acc: 0.8943 - val_loss: 1.1135 - val_acc: 0.6318\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/25\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 0.9105 - acc: 0.8882 - val_loss: 0.9258 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.8281 - acc: 0.9023 - val_loss: 1.0724 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/25\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.8097 - acc: 0.9039 - val_loss: 1.1444 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/25\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.8076 - acc: 0.9059 - val_loss: 1.2068 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/25\n",
      " 35/450 [=>............................] - ETA: 9s - loss: 0.6799 - acc: 0.9268  ETA: 10s - loss: 0.6145 - ac"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-67ce391024ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                     class_mode = 'binary', target_size = (64, 64)), steps_per_epoch = 1800 / 4, epochs = 25, \n\u001b[0;32m      3\u001b[0m                     verbose = 1, validation_data = datagen.flow_from_directory('Partitioned_Data/Validation', \n\u001b[1;32m----> 4\u001b[1;33m                     batch_size = 4, class_mode = 'binary',  target_size = (64, 64)), callbacks = callbacks, class_weight = {0:1, 1:8})\n\u001b[0m",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow_from_directory('Partitioned_Data/Training', batch_size = 16, \n",
    "                    class_mode = 'binary', target_size = (64, 64)), steps_per_epoch = 1800 / 4, epochs = 25, \n",
    "                    verbose = 1, validation_data = datagen.flow_from_directory('Partitioned_Data/Validation', \n",
    "                    batch_size = 4, class_mode = 'binary',  target_size = (64, 64)), callbacks = callbacks, class_weight = {0:1, 1:8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = datagen.flow_from_directory('Partitioned_Data/Validation', target_size = (64, 64), class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for melanoma: 0.14457831325301204\n",
      "F1 score for non-melanoma: 0.7774294670846397\n"
     ]
    }
   ],
   "source": [
    "results = model.predict_generator(test_set)\n",
    "y_true = test_set.classes\n",
    "y_pred = np.rint(results)\n",
    "cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "# Class - Melanoma\n",
    "precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "recall =  cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"F1 score for melanoma:\", f1)\n",
    "\n",
    "# Class - Others\n",
    "precision = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "recall = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"F1 score for non-melanoma:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melonoma f1-score : 0.144\n",
    "### Other f1-score : 0.777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
